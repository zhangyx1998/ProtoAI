# Data Directory

This directory contains the core data processing and AI inference components for ProtoAI.

## Files Overview

- **`data.ts`** - Sample protocol data with combined packet information
- **`dataHandling.js`** - Data processing utilities and handlers
- **`GPT_infer.js`** - Main GPT inference module for protocol analysis
- **`GPT_output.txt`** - Output results from GPT inference operations
- **`processed_data.json`** - Processed and structured protocol data
- **`prompt.txt`** - GPT prompt template for protocol analysis

## Usage

### Running GPT Inference

**⚠️ Important**: Make sure to export your OpenAI API token before running:

```bash
# Windows PowerShell
$env:OPENAI_API_KEY = "your-openai-api-token-here"

# Windows Command Prompt
set OPENAI_API_KEY=your-openai-api-token-here

# macOS/Linux
export OPENAI_API_KEY="your-openai-api-token-here"
```

### Example Usage

```javascript
import { runGPTInference } from './GPT_infer.js';

// Main execution - call the GPT inference function
try {
    console.log('Starting GPT inference workflow...');
    const result = await runGPTInference(combinedData);
    console.log('Workflow completed successfully!');
} catch (error) {
    console.error('Main workflow failed:', error.message);
}
```

## Data Format

The system processes communication protocol data including:
- **DATA-UP/DATA-DOWN packets**: Raw binary data with timestamps and hex payloads
- **USER-HINT entries**: Human-provided context about protocol behavior at specific timestamps

## Output

Results are generated in structured formats for further analysis and visualization in the main ProtoAI application.